
































svm_gamma = 0.001
svm_random_state = 1
svm_class_weight = 'balanced'





random_state = 1
epochs = 300
batch_size = 30





test_size = 0.2








import numpy as np
import pandas as pd
from sklearn import svm
from sklearn.neural_network import MLPClassifier
from sklearn.datasets import load_digits, load_breast_cancer, load_iris, fetch_olivetti_faces, load_wine
from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import time
import matplotlib.pyplot as plt
import seaborn as sns





def m_arcsinh_svm(X, Y):
    """
    Implements m-arcsinh as a kernel function for SVM classifier
    
    Parameters:
    X, Y : numpy.ndarray
        Input arrays to classify
    """
    return np.dot((1/3 * np.arcsinh(X)) * (1/4 * np.sqrt(np.abs(X))),
                  (1/3 * np.arcsinh(Y.T)) * (1/4 * np.sqrt(np.abs(Y.T))))





def m_arcsinh_mlp_torch(X):
    """
    Compute the m-arcsinh hyperbolic function for PyTorch tensors.
    
    Parameters:
    -----------
    X : torch.Tensor, shape (n_samples, n_features)
        The input data.
        
    Returns:
    --------
    X_new : torch.Tensor, shape (n_samples, n_features)
        The transformed data.
    """
    return (1/3 * torch.arcsinh(X)) * (1/4 * torch.sqrt(torch.abs(X)))

def inplace_m_arcsinh_derivative(Z, delta):
    """
    Apply the derivative of the hyperbolic m-arcsinh function.
    
    Parameters:
    -----------
    Z : {array-like, sparse matrix}, shape (n_samples, n_features)
        The data which were output from the hyperbolic m-arcsinh 
        activation function during the forward pass.
    delta : {array-like}, shape (n_samples, n_features)
        The back-propagated error signal to be modified in place.
    """
    delta *= (np.sqrt(np.abs(Z))/(12 * np.sqrt(Z**2 + 1)) + (Z * np.arcsinh(Z))/(24 * np.abs(Z)**(3/2)))

# inplace_m_arcsinh_derivative is not needed as PyTorchâ€™s autograd will automatically differentiate m_arcsinh_mlp_torch

# Custom m-arcsinh activation function in PyTorch
class MArcsinhActivation(nn.Module):
    def forward(self, x):
        return m_arcsinh_mlp_torch(x)

# Custom MLP model class
class MLPModel(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, activation='relu'):
        super(MLPModel, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, output_size)
        
        # Choose activation function
        if activation == 'm_arcsinh':
            self.activation = MArcsinhActivation()
        elif activation == 'relu':
            self.activation = nn.ReLU()
        elif activation == 'tanh':
            self.activation = nn.Tanh()
        elif activation == 'identity':
            self.activation = nn.Identity()
        elif activation == 'sigmoid':
            self.activation = nn.Sigmoid()
        else:
            raise ValueError(f"Unknown activation function: {activation}")
        
    def forward(self, x):
        x = self.fc1(x)
        x = self.activation(x)
        x = self.fc2(x)
        return x











breast_cancer_data_set = load_breast_cancer()
digits_data_set = load_digits()
faces_data_set = fetch_olivetti_faces()
wine_data_set = load_wine()
iris_data_set = load_iris()





# SVM Kernels to compare
def get_svm_results_for_dataset(data_set):
    svm_kernels = {
        'm_arcsinh': m_arcsinh_svm,
        'rbf': 'rbf',
        'linear': 'linear',
        'poly': 'poly',
        'sigmoid': 'sigmoid'
    }
    
    X_train, X_test, y_train, y_test = train_test_split(data_set.data, data_set.target, test_size=test_size, random_state=svm_random_state)
    
    svm_results = []
    for kernel_name, kernel in svm_kernels.items():
        classifier_svm = svm.SVC(kernel=kernel, gamma=svm_gamma, random_state=svm_random_state, class_weight=svm_class_weight)
        
        # Timing and training
        start_time = time.time()
        classifier_svm.fit(X_train, y_train)
        training_time = time.time() - start_time
        
        # Prediction and evaluation
        y_pred = classifier_svm.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        report = classification_report(y_test, y_pred, output_dict=True, zero_division=1)
        
        svm_results.append({
            'Classifier': 'SVM',
            'Function': kernel_name,
            'Training Time (s)': training_time,
            'Accuracy': accuracy,
            'Weighted Precision': report['weighted avg']['precision'],
            'Weighted Recall': report['weighted avg']['recall'],
            'Weighted F1-score': report['weighted avg']['f1-score']
        })

    return svm_results





def get_mlp_results_for_dataset(data_set):
    # Split data
    X_train, X_test, y_train, y_test = train_test_split(
        data_set.data, data_set.target, test_size=test_size, random_state=random_state
    )
    
    # Convert data to PyTorch tensors
    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
    y_train_tensor = torch.tensor(y_train, dtype=torch.long)
    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
    y_test_tensor = torch.tensor(y_test, dtype=torch.long)
    
    # Prepare data loaders
    train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=batch_size, shuffle=False)
    
    # Training function
    def train_model(model, train_loader, criterion, optimizer, epochs=epochs):
        model.train()
        for epoch in range(epochs):
            for inputs, labels in train_loader:
                optimizer.zero_grad()
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()
    
    # Activation functions to test
    activation_functions = ['m_arcsinh', 'identity', 'relu', 'tanh', 'sigmoid']
    mlp_results = []
    
    def evaluate_model(model, test_loader):
        model.eval()
        all_preds = []
        all_labels = []
        with torch.no_grad():
            for inputs, labels in test_loader:
                outputs = model(inputs)
                _, preds = torch.max(outputs, 1)
                all_preds.extend(preds.numpy())
                all_labels.extend(labels.numpy())
        return all_labels, all_preds
        
    def evaluateMLP(activation_function):
        # Initialize model with dynamic output size
        model = MLPModel(
            input_size=X_train.shape[1], hidden_size=100, output_size=500, activation=activation_function
        )
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        
        # Train the model
        start_time = time.time()
        train_model(model, train_loader, criterion, optimizer, epochs=10)
        training_time = time.time() - start_time
        
        # Evaluate the model
        y_true, y_pred = evaluate_model(model, test_loader)
        accuracy = accuracy_score(y_true, y_pred)
        precision = precision_score(y_true, y_pred, average='weighted', zero_division=1)
        recall = recall_score(y_true, y_pred, average='weighted', zero_division=1)
        f1 = f1_score(y_true, y_pred, average='weighted', zero_division=1)
        return {
            'Classifier': 'MLP',
            'Function': activation_function,
            'Training Time (s)': training_time,
            'Accuracy': accuracy,
            'Weighted Precision': precision,
            'Weighted Recall': recall,
            'Weighted F1-score': f1
        }
    
    torch.manual_seed(random_state)
    np.random.seed(random_state)
    
    for afunc in activation_functions:
        mlp_results.append(evaluateMLP(afunc))

    return mlp_results








breast_cancer_results_df = pd.DataFrame(get_svm_results_for_dataset(breast_cancer_data_set) + get_mlp_results_for_dataset(breast_cancer_data_set))
breast_cancer_results_df['Dataset'] = 'Breast Cancer'
breast_cancer_results_df





digits_results_df = pd.DataFrame(get_svm_results_for_dataset(digits_data_set) + get_mlp_results_for_dataset(digits_data_set))
digits_results_df['Dataset'] = 'Digits'
digits_results_df





faces_results_df = pd.DataFrame(get_svm_results_for_dataset(faces_data_set) + get_mlp_results_for_dataset(faces_data_set))
faces_results_df['Dataset'] = 'Faces'
faces_results_df





wine_results_df = pd.DataFrame(get_svm_results_for_dataset(wine_data_set) + get_mlp_results_for_dataset(wine_data_set))
wine_results_df['Dataset'] = 'Wine'
wine_results_df





iris_results_df = pd.DataFrame(get_svm_results_for_dataset(iris_data_set) + get_mlp_results_for_dataset(iris_data_set))
iris_results_df['Dataset'] = 'Iris'
iris_results_df








all_results = pd.concat(
    [breast_cancer_results_df, digits_results_df, faces_results_df, wine_results_df, iris_results_df],
    ignore_index=True
)


def rank_functions(df):
    ranked = df.copy()
    
    # Separating SVM and MLP
    svm = ranked[ranked['Classifier'] == 'SVM']
    mlp = ranked[ranked['Classifier'] == 'MLP']
    
    # Ranking by accuracy (higher is better) and training time (lower is better)
    svm['Accuracy Rank'] = svm['Accuracy'].rank(ascending=False)
    svm['Time Rank'] = svm['Training Time (s)'].rank(ascending=True)
    svm['Overall Rank'] = (svm['Accuracy Rank'] + svm['Time Rank']).rank(ascending=True)
    
    mlp['Accuracy Rank'] = mlp['Accuracy'].rank(ascending=False)
    mlp['Time Rank'] = mlp['Training Time (s)'].rank(ascending=True)
    mlp['Overall Rank'] = (mlp['Accuracy Rank'] + mlp['Time Rank']).rank(ascending=True)
    
    return pd.concat([svm, mlp])

# Applying ranking within each dataset
ranked_results = all_results.groupby('Dataset', group_keys=False).apply(rank_functions)

top_performers = ranked_results.sort_values(['Dataset', 'Overall Rank']).groupby(['Dataset', 'Classifier']).head(1)

top_performers[['Dataset', 'Classifier', 'Function', 'Accuracy', 'Training Time (s)', 'Overall Rank']]


sns.barplot(data=top_performers, x='Dataset', y='Accuracy', hue='Classifier')
plt.title('Top Performers by Accuracy')
plt.show()



