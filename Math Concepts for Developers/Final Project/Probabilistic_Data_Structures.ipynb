{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Ejx-Pt0CeIsB"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Probabilistic Data Structures\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "vVKBt-z1tVMf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## My Research"
      ],
      "metadata": {
        "id": "83HehU9i0EPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What are Probabilistic Data Structures?"
      ],
      "metadata": {
        "id": "Pn20XtQst4BL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Probabilistic data structures** are specialized structures that use **probabilistic algorithms** to estimate certain properties of the stored data. Unlike traditional data structures, which aim for precise and deterministic results, **probabilistic counterparts trade accuracy for efficiency and scalability**. They are adept at handling large datasets, where **traditional methods might be resource-intensive**."
      ],
      "metadata": {
        "id": "23r6DqM-t2R7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Advantages Over Traditional (Deterministic) Data Structures"
      ],
      "metadata": {
        "id": "xUXdb4F6vTrL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probabilistic data structures have notable **advantages**, including:\n",
        "- **Space Efficiency:**\n",
        " - They require less memory, using probabilistic algorithms and techniques like hash functions and **Bloom filters** for compact data representation.\n",
        "- **Speed and Performance:**\n",
        " - By sacrificing some accuracy, they deliver outstanding speed. They employ probabilistic algorithms that allow for quick processing of extensive datasets.\n",
        "- **Memory Optimization:**\n",
        " - In-memory stores like Redis emphasize memory efficiency. Probabilistic data structures, by compressing data, help optimize memory usage, ensuring that Redis can process large datasets without sacrificing performance."
      ],
      "metadata": {
        "id": "wHfF0lOdvXtD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5 of the best Probabilistic Data Structures"
      ],
      "metadata": {
        "id": "HIlGRZ3taooN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are some of the coolest ones (*for me at least*), that I've came across"
      ],
      "metadata": {
        "id": "lef5HdVBvCCT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Bloom Filter**"
      ],
      "metadata": {
        "id": "NX48pPOqa-CW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What is **Bloom Filter**"
      ],
      "metadata": {
        "id": "QOSnSzN8bCje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Bloom filter is a **space-efficient probabilistic data structure**, conceived by Burton Howard Bloom in 1970, that is used to test whether an element is a member of a set. **False positive matches are possible**, but **false negatives are not** – in other words, a query returns either \"possibly in set\" or \"definitely not in set\". Elements can be added to the set, but not removed (though this can be addressed with the counting Bloom filter variant). **The more items added, the larger the probability of false positives.**"
      ],
      "metadata": {
        "id": "WLllpEtRbJtv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### How does Bloom Filter work"
      ],
      "metadata": {
        "id": "nFI-oZzRa0Rt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An empty Bloom filter is a bit array of $m$ bits, all set to **0**. It is equipped with $k$ different hash functions, which map set elements to one of the $m$ possible array positions.\n",
        "\n",
        "- Insertion:\n",
        " - To add an element, feed it to each of the $k$ hash functions to get $k$ array positions. Set the bits at all these positions to **1**.\n",
        "\n",
        "- Search\n",
        " - To know whether an element is in the set, feed it to each of the $k$ hash functions to get $k$ array positions. If any of the bits at these positions is **0**, the element is **definitely NOT in the set**. If all the bits are **1**, then either the element is in the set, or the bits have by chance been set to **1** during the insertion of other elements, resulting in a **false positive**.\n",
        "\n",
        "- Deletion\n",
        " - Removing an element from Bloom filter is impossible because there is no way to tell which of the $k$ bits it maps to should be cleared. Although setting any one of those $k$ bits to zero suffices to remove the element, it would also remove any other elements that happen to map onto that bit. This would cause false negatives.\n"
      ],
      "metadata": {
        "id": "mN5979pL13-g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Advantages\n",
        "While risking false positives, **Bloom filters** have a substantial space advantage over other data structures for representing sets, such as **self-balancing binary search trees, tries, hash tables** . Most of these require storing at least the data items themselves. <br>\n",
        "**Bloom filters** on the other hand do not store the data items at all. The presence of an element is indicated purely by the state of the bits in the array."
      ],
      "metadata": {
        "id": "ua86YM3s9k1x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " A Bloom filter with a **1%** error and an optimal value of $k$, in contrast, requires only about **9.6 bits per element**, regardless of the size of the elements."
      ],
      "metadata": {
        "id": "MIh7HCEkBGM9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The time needed either to add items or to check whether an item is in the set is a fixed constant, **O(k)**, completely independent of the number of items already in the set. **No other constant-space set data structure has this property.**"
      ],
      "metadata": {
        "id": "df6wkk0TBw5v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The math behind Bloom Filter"
      ],
      "metadata": {
        "id": "JZwv3zsACGND"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notation:\n",
        "- $m$: The number of bits in the Bloom Filter.\n",
        "- $k$: The number of hash functions.\n",
        "- $n$: The number of elements inserted into the Bloom Filter."
      ],
      "metadata": {
        "id": "wMqacUp7CaeM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Probability a Certain Bit is Not Set to **1** by a Single Hash Function"
      ],
      "metadata": {
        "id": "aJQVsr_xCjck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A hash function selects each array position with equal probability.\n",
        "- Therefore, the probability that a specific bit is not set to **1** by one hash function during the insertion of an element is:"
      ],
      "metadata": {
        "id": "xpz39FBZqSb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$1- \\frac{1}{m}$$"
      ],
      "metadata": {
        "id": "zhAe-5jsD7_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Probability a Certain Bit is Not Set to **1** by Any of the $k$ Hash Functions"
      ],
      "metadata": {
        "id": "8Jppd7goE1-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- If there are **k** hash functions, the probability that a particular bit is not set to 1 by any of the **k** hash functions is:"
      ],
      "metadata": {
        "id": "HnEafdLSqk31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\\left(1 - \\frac{1}{m}\\right)^k$$"
      ],
      "metadata": {
        "id": "H71yKinCFQpz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Using the Limit for $e^{-1}$"
      ],
      "metadata": {
        "id": "Y_GRcZYWF81-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The identity for $e^{-1}$  is"
      ],
      "metadata": {
        "id": "mvXnr8XDq-lI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\\lim_{m\\to\\infty} \\left(1 - \\frac{1}{m}\\right)^k = \\frac{1}{e}$$"
      ],
      "metadata": {
        "id": "_YND-TGmGHoo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying this to our probability and for large **$m$**, we get:"
      ],
      "metadata": {
        "id": "vpzfunBGrHLg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\\left(1-{\\frac {1}{m}}\\right)^{k}=\\left(\\left(1-{\\frac {1}{m}}\\right)^{m}\\right)^{k/m}\\approx e^{-k/m}$$"
      ],
      "metadata": {
        "id": "habYzIrBrmnT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Probability a Certain Bit is Still **0** After n Insertions"
      ],
      "metadata": {
        "id": "Rr_xAgCBr3Ut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After inserting $n$ elements, each with $k$ hash functions, the probability that a specific bit is still **0** is:"
      ],
      "metadata": {
        "id": "LvQgW0mOsDs-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\\left(1-{\\frac {1}{m}}\\right)^{kn}\\approx e^{-kn/m}$$"
      ],
      "metadata": {
        "id": "vtKCTqUTsbnp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hence, the probability that a specific bit is set to **1** is:"
      ],
      "metadata": {
        "id": "rHOTKqJcsnHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ 1-\\left(1-{\\frac {1}{m}}\\right)^{kn}\\approx 1-e^{-kn/m} $$"
      ],
      "metadata": {
        "id": "O1cFUAzRstFY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### False Positive Probability"
      ],
      "metadata": {
        "id": "xD7J9x57s136"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- When checking membership for an element not in the set, the $k$ hash functions may all point to bits that are **1**.\n",
        "- The probability of false positive is calculated with this formula:"
      ],
      "metadata": {
        "id": "hSP1TwXrs5k6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ \\varepsilon =\\left(1-\\left[1-{\\frac {1}{m}}\\right]^{kn}\\right)^{k}\\approx \\left(1-e^{-kn/m}\\right)^{k }$$"
      ],
      "metadata": {
        "id": "qm-qkkeWtOmU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This approximation assumes independence between the bits, which is not strictly true but gives a close approximation."
      ],
      "metadata": {
        "id": "PRGsxIBTvABe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Alternative Analysis Using Fraction of Bits Set to 0"
      ],
      "metadata": {
        "id": "N5ligyACxV3j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- $q$: Fraction of the $m$ bits still set to **0** after inserting $n$ items.\n",
        "When testing for membership, the probability that a bit is found set to **1** by any hash function is:\n",
        "$$1−q$$\n",
        "\n",
        "- Therefore, the probability that all $k$ hash functions find their bit set to **1** is:\n",
        "\n",
        "$$(1-q)^k$$"
      ],
      "metadata": {
        "id": "rFGN_OVlyTxf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Expected Value of $q$"
      ],
      "metadata": {
        "id": "t2hUnXQzy9Vb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The expected value of $q$ (the fraction of bits still set to **0**) is:"
      ],
      "metadata": {
        "id": "5R8JHHEzzGcd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ E[q]=\\left(1-{\\frac {1}{m}}\\right)^{kn} $$"
      ],
      "metadata": {
        "id": "qwLL_EUXzLxj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Concentration of $q$"
      ],
      "metadata": {
        "id": "65ZPS5g_zk2-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Using the **Azuma-Hoeffding inequality**, it's shown that $q$ is strongly concentrated around its expected value:"
      ],
      "metadata": {
        "id": "6bly9TvgzubY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ \\Pr(\\left|q-E[q]\\right|\\geq {\\frac {\\lambda }{m}})\\leq 2\\exp(-2\\lambda ^{2}/kn) $$"
      ],
      "metadata": {
        "id": "jHfG4JFwz2oo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### False Positive Probability"
      ],
      "metadata": {
        "id": "iP2EFkikz9_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Summing over all possible values of $q$, the false positive probability is approximated as:"
      ],
      "metadata": {
        "id": "YwBH64GJ0Fp5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ \\sum _{t}\\Pr(q=t)(1-t)^{k}\\approx (1-E[q])^{k}=\\left(1-\\left[1-{\\frac {1}{m}}\\right]^{kn}\\right)^{k}\\approx \\left(1-e^{-kn/m}\\right)^{k}$$"
      ],
      "metadata": {
        "id": "H9g4j5Wc0KRi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Optimal Number of Hash Functions"
      ],
      "metadata": {
        "id": "Jy5xTJ0H0cqB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The number of hash functions $k$ that minimizes the false positive probability for given $m$ and $n$ is:"
      ],
      "metadata": {
        "id": "Gka9D4zi0gOL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ k={\\frac {m}{n}}\\ln 2 $$"
      ],
      "metadata": {
        "id": "yviYm8jv0o4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Required Number of Bits"
      ],
      "metadata": {
        "id": "1TLUhx7A0xak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- To achieve a desired false positive probability $\\varepsilon$, the required number of bits $m$ can be computed as follows:"
      ],
      "metadata": {
        "id": "Hpm4W4Bo03wU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Substituting the optimal $k$ into the false positive probability expression:\n",
        "\n",
        "$$ \\varepsilon =\\left(1-e^{-({\\frac {m}{n}}\\ln 2){\\frac {n}{m}}}\\right)^{{\\frac {m}{n}}\\ln 2}=\\left({\\frac {1}{2}}\\right)^{{\\frac {m}{n}}\\ln 2}$$\n",
        "\n",
        "2. Simplifying the above expression:\n",
        "\n",
        "$$ \\ln(\\varepsilon )=-{\\frac {m}{n}}\\ln(2)^{2}$$\n",
        "\n",
        "$$ {\\frac {m}{n}}=-{\\frac {\\ln(\\varepsilon )}{\\ln(2)^{2}}}\\approx -2.08\\ln(\\varepsilon ) $$\n",
        "\n",
        "3. The corresponding number of hash functions (ignoring integrality):\n",
        "\n",
        "$$ k=-{\\frac {\\ln(\\varepsilon )}{\\ln(2)}}$$"
      ],
      "metadata": {
        "id": "ubWwK90Z1N4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Union and Intersection of Sets"
      ],
      "metadata": {
        "id": "KpIvK0h814Ni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Bloom Filters can be used to estimate the sizes of the union and intersection of two sets."
      ],
      "metadata": {
        "id": "Jw7B-b1V3KDK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Estimate Count of Bloom Filters:\n",
        " - For Bloom Filter $A$:\n",
        "\n",
        " $$ n(A^{*})=-{\\frac {m}{k}}\\ln \\left[1-{\\frac {|A|}{m}}\\right] $$\n",
        "\n",
        " - For Bloom Filter $B$\n",
        "\n",
        " $$ n(B^{*})=-{\\frac {m}{k}}\\ln \\left[1-{\\frac {|B|}{m}}\\right] $$"
      ],
      "metadata": {
        "id": "RqqqMSm92JJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Size of Their Union:"
      ],
      "metadata": {
        "id": "--bkrRdD3xOM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ n(A^{*}\\cup B^{*})=-{\\frac {m}{k}}\\ln \\left[1-{\\frac {|A\\cup B|}{m}}\\right] $$\n",
        "*where $ n(A \\cup B) $ is the number of bits set to one in either Bloom Filter.*"
      ],
      "metadata": {
        "id": "T1YpMSOL32FP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Size of Their Intersection:"
      ],
      "metadata": {
        "id": "gbvS6lY63-1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ n(A^{*}\\cap B^{*})=n(A^{*})+n(B^{*})-n(A^{*}\\cup B^{*} ) $$"
      ],
      "metadata": {
        "id": "e6R3n4dL4b8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Code example"
      ],
      "metadata": {
        "id": "hdlImBP85dED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitarray"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QqC4GBQ5sFI",
        "outputId": "84d8dbcc-6cc4-471b-8e50-1774e296168b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitarray\n",
            "  Downloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.3/288.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitarray\n",
            "Successfully installed bitarray-2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "import math\n",
        "from bitarray import bitarray\n",
        "\n",
        "class BloomFilter:\n",
        "    def __init__(self, num_items, false_positive_rate):\n",
        "        self.num_items = num_items\n",
        "        self.false_positive_rate = false_positive_rate\n",
        "\n",
        "        # Calculating the size of the bit array (m) and number of hash functions (k)\n",
        "        self.size = -int((num_items * math.log(false_positive_rate)) / (math.log(2) ** 2))\n",
        "        self.num_hashes = int((self.size / num_items) * math.log(2))\n",
        "\n",
        "        # Initializing bit array to all 0's\n",
        "        self.bit_array = bitarray(self.size)\n",
        "        self.bit_array.setall(0)\n",
        "\n",
        "    def _hashes(self, item):\n",
        "        \"\"\"Generate k hash values for the given item.\"\"\"\n",
        "        hash1 = int(hashlib.md5(item.encode()).hexdigest(), 16)\n",
        "        hash2 = int(hashlib.sha1(item.encode()).hexdigest(), 16)\n",
        "        for i in range(self.num_hashes):\n",
        "            yield (hash1 + i * hash2) % self.size\n",
        "\n",
        "    def add(self, item):\n",
        "        \"\"\"Add an item to the Bloom Filter.\"\"\"\n",
        "        for index in self._hashes(item):\n",
        "            self.bit_array[index] = 1\n",
        "\n",
        "    def contains(self, item):\n",
        "        \"\"\"Check if an item is in the Bloom Filter.\"\"\"\n",
        "        return all(self.bit_array[index] for index in self._hashes(item))\n",
        "\n",
        "    def estimate_items(self):\n",
        "        \"\"\"Estimate the number of items in the Bloom Filter.\"\"\"\n",
        "        X = self.bit_array.count(1)\n",
        "        m = self.size\n",
        "        k = self.num_hashes\n",
        "        return - (m / k) * math.log(1 - X / m)\n",
        "\n",
        "    def union(self, other):\n",
        "        \"\"\"Return a new Bloom Filter that represents the union of this and another Bloom Filter.\"\"\"\n",
        "        if self.size != other.size or self.num_hashes != other.num_hashes:\n",
        "            raise ValueError(\"Bloom Filters must have the same size and number of hash functions to union\")\n",
        "        result = BloomFilter(self.num_items, self.false_positive_rate)\n",
        "        result.bit_array = self.bit_array | other.bit_array\n",
        "        return result\n",
        "\n",
        "    def intersection(self, other):\n",
        "        \"\"\"Return a new Bloom Filter that represents the intersection of this and another Bloom Filter.\"\"\"\n",
        "        if self.size != other.size or self.num_hashes != other.num_hashes:\n",
        "            raise ValueError(\"Bloom Filters must have the same size and number of hash functions to intersect\")\n",
        "        result = BloomFilter(self.num_items, self.false_positive_rate)\n",
        "        result.bit_array = self.bit_array & other.bit_array\n",
        "        return result\n",
        "\n",
        "bf = BloomFilter(num_items=100, false_positive_rate=0.01)\n",
        "\n",
        "items_to_add = [\"apple\", \"banana\", \"cherry\", \"cucumber\", \"tomato\"]\n",
        "for item in items_to_add:\n",
        "    bf.add(item.lower())\n",
        "\n",
        "# Check\n",
        "items_to_check = [\"Apple\", \"banana\", \"peach\", \"grape\"]\n",
        "for item in items_to_check:\n",
        "    print(f\"{item} in Bloom Filter: {bf.contains(item.lower())}\")\n",
        "\n",
        "# Estimating the number of items in the Bloom Filter\n",
        "print(f\"Estimated number of items: {bf.estimate_items()}\")\n",
        "\n",
        "# Creating another Bloom Filter and perform union and intersection\n",
        "bf2 = BloomFilter(num_items=100, false_positive_rate=0.01)\n",
        "other_items_to_add = [\"peach\", \"grape\", \"honeydew\", \"banana\"]\n",
        "for item in other_items_to_add:\n",
        "    bf2.add(item.lower())\n",
        "\n",
        "# Union\n",
        "union_bf = bf.union(bf2)\n",
        "print(f\"Estimated number of items in union: {union_bf.estimate_items()}\")\n",
        "\n",
        "# Intersection\n",
        "intersection_bf = bf.intersection(bf2)\n",
        "print(f\"Estimated number of items in intersection: {intersection_bf.estimate_items()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVRB6I_B5kQC",
        "outputId": "352270c0-210e-4c42-f12d-27d5c6a3f812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple in Bloom Filter: True\n",
            "banana in Bloom Filter: True\n",
            "peach in Bloom Filter: False\n",
            "grape in Bloom Filter: False\n",
            "Estimated number of items: 5.0799618811507035\n",
            "Estimated number of items in union: 8.032012620174063\n",
            "Estimated number of items in intersection: 1.1709498962667566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Skip List**"
      ],
      "metadata": {
        "id": "ZpvCCjZMw9KJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What is **Skip List**"
      ],
      "metadata": {
        "id": "5eK6PBBaHVeq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A skip list is a probabilistic data structure that provides efficient $O(\\log{n})$ average time complexity for search and insertion operations within an ordered sequence of $n$ elements. It combines the best features of a **sorted array** and a **linked list**, allowing for fast search operations and dynamic insertion capabilities."
      ],
      "metadata": {
        "id": "EtBzVj79HbsT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Structure"
      ],
      "metadata": {
        "id": "p0v6-LvsH2dX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Layers**: A skip list is composed of multiple layers of **linked lists**. The bottom layer (Layer 1) is a standard ordered linked list containing all the elements. Each higher layer acts as an \"express lane\", skipping over more elements.\n",
        "- **Probability**: An element in layer $i$ appears in layer $i+1$ with a fixed probability $p$. Common values for $p$ are $1/2$ or $1/4$. This means, on average, each element appears in $1/(1-p)$ lists.\n",
        "- **Height**: The expected number of layers is $\\log_{1/p}{n}$, where $n$ is the number of elements."
      ],
      "metadata": {
        "id": "gerhr0hEH7yv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Search"
      ],
      "metadata": {
        "id": "3NQ6q0V2I5KX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Start at the **topmost layer** and move **horizontally** until the current element is **greater than or equal to the target**. If it is equal, the search is successful. **If greater, drop down to the next lower layer and continue the search**."
      ],
      "metadata": {
        "id": "AfORV5D3I62t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Insertion"
      ],
      "metadata": {
        "id": "bOxoGGgIIsos"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Similar to search, but elements are inserted at appropriate positions in multiple layers based on the probability $p$."
      ],
      "metadata": {
        "id": "9iVyRg5CIv_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### The math behind Skip List"
      ],
      "metadata": {
        "id": "rckSBUQsJRWg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is not much, since it is a pretty simple data structure."
      ],
      "metadata": {
        "id": "NT1QgYZSJX_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Search Complexity**: The expected number of steps in each layer is $1/p$, leading to a total expected search cost of $1/p * \\log_{1/p} {n}$, which simplifies to $O(\\log{n})$ for constant $p$.\n",
        "\n",
        "- **Insertion Complexity**: Insertion also has an average complexity of $O(\\log {n})$."
      ],
      "metadata": {
        "id": "sjhXxj2KJj4i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Code Example"
      ],
      "metadata": {
        "id": "CcAP6k6IKIq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class Node:\n",
        "    def __init__(self, value, level):\n",
        "        self.value = value\n",
        "        self.forward = [None] * (level + 1)\n",
        "\n",
        "class SkipList:\n",
        "    def __init__(self, max_level, p):\n",
        "        self.max_level = max_level\n",
        "        self.p = p\n",
        "        self.header = self.create_node(self.max_level, -1)\n",
        "        self.level = 0\n",
        "\n",
        "    def create_node(self, level, value):\n",
        "        return Node(value, level)\n",
        "\n",
        "    def random_level(self):\n",
        "        level = 0\n",
        "        while random.random() < self.p and level < self.max_level:\n",
        "            level += 1\n",
        "        return level\n",
        "\n",
        "    def insert(self, value):\n",
        "        update = [None] * (self.max_level + 1)\n",
        "        current = self.header\n",
        "\n",
        "        for i in range(self.level, -1, -1):\n",
        "            while current.forward[i] and current.forward[i].value < value:\n",
        "                current = current.forward[i]\n",
        "            update[i] = current\n",
        "\n",
        "        level = self.random_level()\n",
        "\n",
        "        if level > self.level:\n",
        "            for i in range(self.level + 1, level + 1):\n",
        "                update[i] = self.header\n",
        "            self.level = level\n",
        "\n",
        "        new_node = self.create_node(level, value)\n",
        "\n",
        "        for i in range(level + 1):\n",
        "            new_node.forward[i] = update[i].forward[i]\n",
        "            update[i].forward[i] = new_node\n",
        "\n",
        "    def search(self, value):\n",
        "        current = self.header\n",
        "\n",
        "        for i in range(self.level, -1, -1):\n",
        "            while current.forward[i] and current.forward[i].value < value:\n",
        "                current = current.forward[i]\n",
        "\n",
        "        current = current.forward[0]\n",
        "\n",
        "        if current and current.value == value:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def display_list(self):\n",
        "        for i in range(self.level + 1):\n",
        "            print(f\"Level {i}: \", end=\"\")\n",
        "            node = self.header.forward[i]\n",
        "            while node:\n",
        "                print(node.value, end=\" \")\n",
        "                node = node.forward[i]\n",
        "            print(\"\")\n",
        "\n",
        "max_level = 4\n",
        "p = 0.5\n",
        "skiplist = SkipList(max_level, p)\n",
        "\n",
        "elements = [3, 6, 7, 9, 12, 19, 17, 26, 21]\n",
        "for elem in elements:\n",
        "    skiplist.insert(elem)\n",
        "\n",
        "skiplist.display_list()\n",
        "\n",
        "search_elements = [19, 6, 21, 25]\n",
        "for elem in search_elements:\n",
        "    found = skiplist.search(elem)\n",
        "    print(f\"Element {elem} {'found' if found else 'not found'} in the skip list\")\n"
      ],
      "metadata": {
        "id": "9thsG3bGw_Eq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96e04137-7a13-4ea9-8294-bdcff1c404a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Level 0: 3 6 7 9 12 17 19 21 26 \n",
            "Level 1: 3 7 12 17 \n",
            "Level 2: 17 \n",
            "Level 3: 17 \n",
            "Element 19 found in the skip list\n",
            "Element 6 found in the skip list\n",
            "Element 21 found in the skip list\n",
            "Element 25 not found in the skip list\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **HyperLogLog**"
      ],
      "metadata": {
        "id": "Ejx-Pt0CeIsB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What is **HyperLogLog**"
      ],
      "metadata": {
        "id": "a58yoMfugUZW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "HyperLogLog is a probabilistic algorithm designed to estimate the **number of distinct elements** in a multiset. It is particularly effective for large datasets where storing exact counts would be impractical. This algorithm uses significantly less memory than traditional methods while maintaining a high level of accuracy."
      ],
      "metadata": {
        "id": "6s-oTwvggYcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Advantages of using HyperLogLog"
      ],
      "metadata": {
        "id": "u7bBVFm9gihF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Memory Efficiency**: HyperLogLog can estimate cardinalities over **109109** with typical accuracy (standard error) of around **2%**, using just **1.5 KB of memory**.\n",
        "\n",
        "- **Origin**: It builds on the earlier **LogLog** algorithm and the Flajolet-Martin algorithm from 1984.\n",
        "\n",
        "- **Accuracy**: Achieves high accuracy with a relative error of about $1.04/m$\n",
        "​, where $m$ is the number of registers."
      ],
      "metadata": {
        "id": "PvVXGmgsgl0D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### How does it work?"
      ],
      "metadata": {
        "id": "-aJrqpa-hPZt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The core idea is to estimate the cardinality of a multiset by **evaluating the maximum number of leading zeros in the binary representation of each element**. For a multiset of uniformly distributed random numbers:\n",
        "\n",
        "- **Estimate**: If the maximum number of leading zeros in the binary representation of the elements is $n$, the estimate for the number of distinct elements is $2^n$.\n",
        "\n",
        "- **Hashing**: Apply a hash function to each element to obtain a uniformly distributed random number.\n",
        "- **Binary Analysis**: For each hashed value, determine the number of leading zeros. The maximum count of leading zeros across all elements is used to estimate the cardinality."
      ],
      "metadata": {
        "id": "TLl3bTA7hSwg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Operations and mathematical analysis"
      ],
      "metadata": {
        "id": "ZKzmPLr89f0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Legend:\n",
        "- $v$ => input data\n",
        "- $h$ => hash function\n",
        "- $b$ => bits, where $b$ is $\\log _{2}(m)$\n",
        "- $ \\rho (w)$ => number of leading zeros\n",
        "- $M$ => Array of $m$ counters (or \"registers\") that are initialized to **0**"
      ],
      "metadata": {
        "id": "bnuaqiAs-mMT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Addition:"
      ],
      "metadata": {
        "id": "hQc9cqaF9o4i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Hashing**:\n",
        " - Compute the hash $x=h(v)$\n",
        "\n",
        "- **Register Index**:\n",
        " - Determine the register $j$ using the first $b$ bits $j=1+\\langle x_{1}x_{2}...x_{b}\\rangle _{2}$\n",
        "\n",
        "- **Leading Zeros**:\n",
        " - Compute $ρ(w)$, where $w$ is the remaining bits after the first $b$.\n",
        "\n",
        "- **Update**:\n",
        " - Set $M[j]=max(M[j],\\rho (w))$"
      ],
      "metadata": {
        "id": "0orXzMuU9reK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mathematically speaking:\n",
        "$$\\begin{aligned}x&:=h(v)\\\\j&:=1+\\langle x_{1}x_{2}...x_{b}\\rangle _{2}\\\\w&:=x_{b+1}x_{b+2}...\\\\M[j]&:=\\max(M[j],\\rho (w))\\\\\\end{aligned}$$"
      ],
      "metadata": {
        "id": "Lx4H_laoAAL9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RsuolLI95Ksb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Count operation:"
      ],
      "metadata": {
        "id": "DGchhCA4ASZv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Estimate the cardinality using the harmonic mean of the registers:\n",
        "\n",
        "$$ Z={\\Bigg (}\\sum _{j=1}^{m}{2^{-M[j]}}{\\Bigg )}^{-1}$$\n",
        "\n",
        "- The constant $\\alpha_m$ corrects the bias:\n",
        "\n",
        "$$ \\alpha _{m}=\\left(m\\int _{0}^{\\infty }\\left(\\log _{2}\\left({\\frac {2+u}{1+u}}\\right)\\right)^{m}\\,du\\right)^{-1}$$\n",
        "\n",
        "- The cardinality estimate $E$ is:\n",
        "\n",
        "$$E=\\alpha _{m}m^{2}Z$$"
      ],
      "metadata": {
        "id": "6qKt7TIxAXvH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Practical Considerations\n"
      ],
      "metadata": {
        "id": "aEWAgdBlBDxV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Bias Correction**: The constant $\\alpha_m$ is approximated as:\n",
        "\n",
        " $$\n",
        "  \\alpha _{m}\\approx {\\begin{cases}0.673,&{\\text{for }}m=16;\\\\0.697,&{\\text{for }}m=32;\\\\0.709,&{\\text{for }}m=64;\\\\{\\frac {0.7213}{1+1.079/m}},&{\\text{for }}m\\geq 128.\\end{cases}}\n",
        " $$\n",
        "\n",
        "- **Small Cardinalities**: For cardinalities below $\\frac {5}{2}m$, use Linear Counting:\n",
        "\n",
        "$$ E^{\\star }=m\\log \\left({\\frac {m}{V}}\\right) $$ where $V$ is the count of zero registers.\n",
        "\n",
        "- **Large Cardinalities**: For cardinalities exceeding $\\frac{2^{32}}{30}$:\n",
        "\n",
        "$$ E^{\\star }=-2^{32}\\log \\left(1-{\\frac {E}{2^{32}}}\\right)$$\n",
        "\n",
        "- **Error Estimation**: The standard deviation of the estimate is given by:\n",
        "\n",
        "$$\\sigma =\\frac{1.04}{\\sqrt {m}}$$"
      ],
      "metadata": {
        "id": "3ybDZwsIBKre"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Merge operation:"
      ],
      "metadata": {
        "id": "eoOG95MMB8HU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To combine two HyperLogLogs:\n",
        "\n",
        "$${\\mathit {hll}}_{\\text{union}}[j]=\\max({\\mathit {hll}}_{1}[j],{\\mathit {hll}}_{2}[j])$$"
      ],
      "metadata": {
        "id": "dmQoPmbQC668"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Complexity Analysis"
      ],
      "metadata": {
        "id": "GWjglpeLC_Wk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Memory**:\n",
        " - Uses $ O(\\epsilon ^{-2}\\log \\log n+\\log n) $  space, where $n$ is the number of elements and $m$ is the number of registers.\n",
        "\n",
        "- **Add Operation**:\n",
        " - $O(1)$, given a fixed-size hash output.\n",
        "\n",
        "- **Count and Merge**:\n",
        " - Typically $O(m)$, with some implementations considering it $O(1)$"
      ],
      "metadata": {
        "id": "_gHXzLdjDXOH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Code Example"
      ],
      "metadata": {
        "id": "jtyn1L_HEEaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "import math\n",
        "\n",
        "class HyperLogLog:\n",
        "    def __init__(self, m):\n",
        "        self.m = m\n",
        "        self.registers = [0] * m\n",
        "        self.alpha_m = self.get_alpha(m)\n",
        "\n",
        "    def get_alpha(self, m):\n",
        "        if m == 16:\n",
        "            return 0.673\n",
        "        elif m == 32:\n",
        "            return 0.697\n",
        "        elif m == 64:\n",
        "            return 0.709\n",
        "        else:\n",
        "            return 0.7213 / (1 + 1.079 / m)\n",
        "\n",
        "    def add(self, value):\n",
        "        x = int(hashlib.md5(value.encode('utf8')).hexdigest(), 16)\n",
        "        b = int(math.log2(self.m))\n",
        "        j = (x >> (128 - b)) & (self.m - 1)\n",
        "        w = x & ((1 << (128 - b)) - 1)\n",
        "        self.registers[j] = max(self.registers[j], self.rho(w))\n",
        "\n",
        "    def rho(self, w):\n",
        "        bin_w = bin(w)[2:]\n",
        "        return 1 + len(bin_w) - len(bin_w.lstrip('0'))\n",
        "\n",
        "    def count(self):\n",
        "        Z = 1.0 / sum([2 ** (-reg) for reg in self.registers])\n",
        "        E = self.alpha_m * self.m * self.m * Z\n",
        "        V = sum(1 for reg in self.registers if reg == 0)\n",
        "        if E < (5 / 2) * self.m:\n",
        "            return self.m * math.log(self.m / V)\n",
        "        else:\n",
        "            return E\n",
        "\n",
        "    def merge(self, other):\n",
        "        for j in range(self.m):\n",
        "            self.registers[j] = max(self.registers[j], other.registers[j])\n",
        "\n",
        "hll1 = HyperLogLog(4096)\n",
        "hll2 = HyperLogLog(4096)\n",
        "\n",
        "for elem in ['apple', 'banana', 'cherry', 'date', 'peach', 'grape', 'melon', 'fig', 'kiwi', 'pineapple', 'apricot','apple']: # 12 elements with repeating apple\n",
        "  hll1.add(elem)\n",
        "  hll2.add(elem)\n",
        "\n",
        "hll1.merge(hll2)\n",
        "\n",
        "print(f\"Estimated cardinality: {hll1.count()}\")"
      ],
      "metadata": {
        "id": "2SOmFEW5eKx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6ea58f5-55ca-4c62-d149-536331f71d22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated cardinality: 11.014797005785086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Count–min sketch**"
      ],
      "metadata": {
        "id": "OMjDgjK4Wpsn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count-Min Sketch is a probabilistic data structure used for **efficiently counting the frequency of events in a data stream**. It provides approximate counts with a guaranteed error bound using **sub-linear space**. Invented by Graham Cormode and S. Muthu Muthukrishnan in 2003, it is particularly useful for large-scale data processing where exact counting is impractical."
      ],
      "metadata": {
        "id": "iLOsv8csTRqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Advantages of using Count-min sketch"
      ],
      "metadata": {
        "id": "T8EgKpOlTjz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Probabilistic**: Offers approximate counts with a controlled error margin.\n",
        "- **Space-Efficient**: Requires sub-linear space relative to the number of unique elements.\n",
        "- **Mergeable**: Sketches from different data streams can be combined."
      ],
      "metadata": {
        "id": "UJJ0xOJgToG6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Structure"
      ],
      "metadata": {
        "id": "UGxJ2sN8T8LE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Count-Min Sketch** consists of a two-dimensional array (table) with $d$ rows and $w$ columns. Each row is associated with a **unique hash function**. The parameters $w$ and $d$ are chosen based on the desired error bounds:\n",
        "\n",
        "- $w=\\lceil e/\\epsilon \\rceil$: Determines the number of columns, related to the approximation error $\\varepsilon$.\n",
        "- $d=\\lceil \\ln⁡(1/\\delta) \\rceil$: Determines the number of rows, related to the confidence level $1-\\delta$."
      ],
      "metadata": {
        "id": "xbpTxHPdT-NY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Adding an Event"
      ],
      "metadata": {
        "id": "04ePnNCDVsCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When a new event of type $i$ arrives:\n",
        "\n",
        "- For each row $j$:\n",
        "\n",
        " - Compute the column index $k=h_j(i)$ using the hash function for that row.\n",
        " - Increment the value in row $j$, column $k$ by **1**."
      ],
      "metadata": {
        "id": "2HSWImFiWC6Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Universe of event types\n",
        "The universe of event types $\\mathcal{U} $ refers to the **set of all possible distinct events that could appear in the data stream**. At any given time, the sketch can be queried for the frequency of a particular event type $i$ from this universe. The sketch returns an estimate of the frequency that is within a certain distance of the true frequency, with a specified probability.\n",
        "\n",
        "*For example, if you are monitoring network traffic, the universe of event types could be all possible IP addresses that might appear in the traffic. If you are counting words in a large collection of documents, the universe could be all possible words.*"
      ],
      "metadata": {
        "id": "4EebJCbSgo9e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Querying Frequency"
      ],
      "metadata": {
        "id": "mAAfls94WiGk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To estimate the frequency of an event type $i$:\n",
        "\n",
        "1. Compute the column index for each row using the hash functions.\n",
        "2. Return the minimum value from these columns.\n",
        "\n",
        "The estimate $\\hat{a}_i​$ of the true frequency $\\hat{a}_i​$​ satisfies:\n",
        "\n",
        "$$a_i \\le \\hat{a}_i \\le a_i + \\epsilon N$$\n",
        "\n",
        "with probability $1−\\delta$, where $N$ is the total number of events processed.\n",
        "\n",
        "$$N=\\sum_{i\\in {\\mathcal {U}}}a_{i}$$"
      ],
      "metadata": {
        "id": "ozyVXkIbWkw5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Mathematical Analysis"
      ],
      "metadata": {
        "id": "JmyUumjSawD3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Error Bounds"
      ],
      "metadata": {
        "id": "ddHT2WiCa2N-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Count-Min Sketch guarantees that the estimated frequency $\\hat{a} _i$ of an event $i$ is within $\\epsilon N$ of the true frequency $a_i$​ with probability $1 - \\delta$:\n",
        "\n",
        "$$\\hat{a}_i \\le a_i + \\epsilon N$$"
      ],
      "metadata": {
        "id": "TyPZ9y3ebCSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Parameter Selection"
      ],
      "metadata": {
        "id": "rH40fSmDbbWu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Width** $w$: Controls the approximation error $\\epsilon$.\n",
        "\n",
        "$$w=\\lceil e/\\epsilon \\rceil$$\n",
        "\n",
        "- **Depth** $\\delta$: Controls the confidence level $1 - \\delta$.\n",
        "\n",
        "$$d=\\lceil \\ln⁡(1/\\delta) \\rceil$$"
      ],
      "metadata": {
        "id": "4ipVTdbPc6Zp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Complexity"
      ],
      "metadata": {
        "id": "0EXhKklIehFW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Time complexity:\n",
        " - **Insert(key)**: $O(d)$\n",
        " - **Query(key)**: $O(d)$\n",
        "\n",
        "Both are constant, considering the number of hashing functions would be constant."
      ],
      "metadata": {
        "id": "QhQ7HzzYh6vw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Space complexity\n",
        " - $O(wd)$, it can be considered constant as well because it does not essentially depend on the number of keys inserted.\n",
        "\n",
        " Given the parameters $w$ and $d$, the space required is significantly less than a traditional hash table, making it suitable for large-scale data processing."
      ],
      "metadata": {
        "id": "7JLXUsbzelu5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Practical consideration"
      ],
      "metadata": {
        "id": "eS97ad_Ii6rM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Bias and Error Reduction**: Several techniques, such as hCount* and Maximum Likelihood Estimation (MLE), can be used to reduce bias and improve accuracy.\n",
        "\n",
        "- **Mergeability**: Count-Min Sketches can be merged by element-wise addition, making it useful for distributed data processing."
      ],
      "metadata": {
        "id": "wiJDb21MjAjR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Code Example"
      ],
      "metadata": {
        "id": "xikCsoMsZOLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import hashlib\n",
        "\n",
        "class CountMinSketch:\n",
        "    def __init__(self, width, depth):\n",
        "        self.width = width\n",
        "        self.depth = depth\n",
        "        self.table = np.zeros((depth, width), dtype=int)\n",
        "        self.hashes = [self._hash_function(seed) for seed in range(depth)]\n",
        "\n",
        "    def _hash_function(self, seed):\n",
        "        def hash_fn(x):\n",
        "            return int(hashlib.md5((str(seed) + str(x)).encode()).hexdigest(), 16) % self.width\n",
        "        return hash_fn\n",
        "\n",
        "    def add(self, item):\n",
        "        for i, hash_fn in enumerate(self.hashes):\n",
        "            self.table[i, hash_fn(item)] += 1\n",
        "\n",
        "    def query(self, item):\n",
        "        return min(self.table[i, hash_fn(item)] for i, hash_fn in enumerate(self.hashes))\n",
        "\n",
        "cms = CountMinSketch(width=2000, depth=5)\n",
        "events = ['apple', 'banana', 'apple', 'pineapple', 'banana', 'apple']\n",
        "\n",
        "for event in events:\n",
        "    cms.add(event)\n",
        "\n",
        "print(f\"Estimated count for 'apple': {cms.query('apple')}\")\n",
        "print(f\"Estimated count for 'banana': {cms.query('banana')}\")\n",
        "print(f\"Estimated count for 'pineapple': {cms.query('pineapple')}\")\n",
        "print(f\"Estimated count for 'peach': {cms.query('peach')}\")\n",
        "\n",
        "for _ in range(100_000):\n",
        "    cms.add(random.choice(events))\n",
        "\n",
        "print(f\"100 000 random items added\")\n",
        "print(f\"Estimated count for 'apple': {cms.query('apple')}\")\n",
        "print(f\"Estimated count for 'banana': {cms.query('banana')}\")\n",
        "print(f\"Estimated count for 'pineapple': {cms.query('pineapple')}\")\n",
        "print(f\"Estimated count for 'peach': {cms.query('peach')}\")\n"
      ],
      "metadata": {
        "id": "IIe2VFOEEG2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5018f804-dda8-4bcb-f7c7-6d63fb1338de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated count for 'apple': 3\n",
            "Estimated count for 'banana': 2\n",
            "Estimated count for 'pineapple': 1\n",
            "Estimated count for 'peach': 0\n",
            "100 000 random items added\n",
            "Estimated count for 'apple': 50037\n",
            "Estimated count for 'banana': 33161\n",
            "Estimated count for 'pineapple': 16808\n",
            "Estimated count for 'peach': 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Quotient Filter**"
      ],
      "metadata": {
        "id": "EpwwBVdbWw4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quotient Filter** is a space-efficient probabilistic data structure introduced by Michael Bender and colleagues in 2011. It is used to manage a set of elements and supports four key operations:\n",
        "- **Adding** elements\n",
        "- **Deleting** elements\n",
        "- **Checking membership**\n",
        "- **Checking non-membership**\n",
        "\n",
        "It offers benefits similar to **Bloom filters** but with different trade-offs in terms of space and performance."
      ],
      "metadata": {
        "id": "ygEm0Ug0W2tw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Advantages of using **Quotient filter**"
      ],
      "metadata": {
        "id": "4UI7my_wYM5i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Space-Efficient**: Uses less space compared to traditional hash tables.\n",
        "- **Probabilistic**: May produce false positives but never false negatives.\n",
        "- **Supports Deletion**: Unlike Bloom filters, quotient filters can efficiently delete elements.\n",
        "- **Mergeable**: Multiple quotient filters can be merged without affecting their false positive rates."
      ],
      "metadata": {
        "id": "sQkCq9zUYRLC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Structure:"
      ],
      "metadata": {
        "id": "__60ls7dYsfl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **quotient filter** relies on two parameters:\n",
        "- $p$: Size (in bits) for fingerprints.\n",
        "- $q$: Determines the number of buckets $(m=2^q)$ in the hash table.\n",
        "\n",
        "The filter uses one hash function that generates $p$-bit fingerprints for the elements. These fingerprints are divided into:\n",
        "- Quotient $(f_q)$: The most significant $q$ bits.\n",
        "- Remainder $(f_r)$: The least significant $p−q$ bits.\n",
        "\n",
        "Each bucket in the hash table contains three status bits:\n",
        "- **is_occupied**: Indicates if the bucket is the canonical bucket (home position) for some fingerprint.\n",
        "- **is_continuation**: Indicates if the bucket is part of a run but not the first bucket of the run.\n",
        "- **is_shifted**: Indicates if the fingerprint in the bucket has been shifted from its canonical position."
      ],
      "metadata": {
        "id": "NYRB43rHYyI1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Operations"
      ],
      "metadata": {
        "id": "Lx41Er3baPnY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Adding an Element"
      ],
      "metadata": {
        "id": "9_annZpkcL7O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Hash the element to produce fingerprint $f$\n",
        "2. Calculate the quotient $f_q$ and remainder $f_r$ from the fingerprint.\n",
        "3. Locate the canonical bucket using the quotient.\n",
        "4. Insert the remainder f_r into the correct position within the run, maintaining sorted order.\n",
        "5. Shift elements if necessary to maintain the contiguous run structure."
      ],
      "metadata": {
        "id": "K55g55vicabV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Deleting an Element"
      ],
      "metadata": {
        "id": "ZXINO2Z7d3ma"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Locate the canonical bucket using the quotient.\n",
        "2. Find the run that the element belongs to.\n",
        "3. Remove the element by adjusting the remainders and status bits appropriately."
      ],
      "metadata": {
        "id": "_j9AKVjJd6nI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Testing Membership"
      ],
      "metadata": {
        "id": "RoRmP1aLeL9K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Hash the element to produce fingerprint $f$\n",
        "2. Calculate the quotient $f_q$ and remainder $f_r$\n",
        "3. Check the canonical bucket for occupancy.\n",
        "4. Scan the run if the canonical bucket is occupied, comparing stored remainders with $f_r$\n",
        "5. Determine membership based on the comparison:\n",
        "  - If a matching remainder is found, the element is probably in the set.\n",
        "  - If not found, the element is definitely not in the set."
      ],
      "metadata": {
        "id": "8eyEtMYiePbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Mathematical Analysis"
      ],
      "metadata": {
        "id": "ykrvHMOIe7AB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### False Positives and False Negatives"
      ],
      "metadata": {
        "id": "lY7ehLZge--g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **False Positives**: The quotient filter may report an element as present when it is not. The probability of a false positive is given by:\n",
        "\n",
        "$$P(\\text{false positive}) \\le \\frac{1}{2^r}$$\n",
        "\n",
        "where $r$ is the number of bits in the remainder.\n",
        "\n",
        "- **False Negatives**: Quotient filters do not produce false negatives. If the filter reports that an element is not present, it is **definitely NOT** in the set."
      ],
      "metadata": {
        "id": "lg7DjD3dfPWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Space Complexity"
      ],
      "metadata": {
        "id": "Bf9LqFoYhNA_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The space complexity is determined by the number of buckets $m=2^q$ and the size of the fingerprints $p$\n",
        "\n",
        "$$Space=m×(\\text{bits per bucket})$$\n",
        "\n",
        "where each bucket typically requires a few status bits plus the remainder bits."
      ],
      "metadata": {
        "id": "RqkSC1UjhTGv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Practical Considerations"
      ],
      "metadata": {
        "id": "7J_LWGWrhtoT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Efficiency**: Quotient filters are generally faster than **Bloom filters** because they only require evaluating a single hash function per operation.\n",
        "\n",
        "- **Mergeability**: Two quotient filters can be merged efficiently without affecting their false positive rates, which is not possible with Bloom filters.\n",
        "\n",
        "- **Deletion**: The quotient filter supports element deletion, which **Bloom filters do not support natively**.\n"
      ],
      "metadata": {
        "id": "HLpF1MKWhw1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Comparison with Bloom Filter"
      ],
      "metadata": {
        "id": "KAyV6Z3miFjG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Space Usage**: Quotient filters are about **20% larger** than **Bloom filters**.\n",
        "- **Performance**: Quotient filters have **faster insert and lookup times** due to requiring fewer hash function evaluations and cache misses.\n",
        "- **Deletion**: Quotient filters **support deletion** of elements, while **Bloom filters** do not."
      ],
      "metadata": {
        "id": "SlyiBKXXiIJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Code example"
      ],
      "metadata": {
        "id": "n5WGLlm3iWzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class QuotientFilter:\n",
        "    def __init__(self, q, p):\n",
        "        self.q = q\n",
        "        self.p = p\n",
        "        self.m = 2 ** q\n",
        "        self.table = [{'occupied': False, 'continuation': False, 'shifted': False, 'remainder': None} for _ in range(self.m)]\n",
        "\n",
        "    def _hash(self, x):\n",
        "        return hash(x) % (2 ** self.p)\n",
        "\n",
        "    def _get_quotient_remainder(self, f):\n",
        "        quotient = f >> (self.p - self.q)\n",
        "        remainder = f & ((1 << (self.p - self.q)) - 1)\n",
        "        return quotient, remainder\n",
        "\n",
        "    def add(self, x):\n",
        "        f = self._hash(x)\n",
        "        fq, fr = self._get_quotient_remainder(f)\n",
        "        self._insert(fq, fr)\n",
        "\n",
        "    def _insert(self, fq, fr):\n",
        "        pos = fq\n",
        "        while self.table[pos]['occupied']:\n",
        "            if pos == fq:\n",
        "                self.table[pos]['shifted'] = True\n",
        "            pos = (pos + 1) % self.m\n",
        "\n",
        "        self.table[pos] = {'occupied': True, 'continuation': False, 'shifted': pos != fq, 'remainder': fr}\n",
        "\n",
        "    def contains(self, x):\n",
        "        f = self._hash(x)\n",
        "        fq, fr = self._get_quotient_remainder(f)\n",
        "        return self._find(fq, fr)\n",
        "\n",
        "    def _find(self, fq, fr):\n",
        "        pos = fq\n",
        "        while self.table[pos]['occupied']:\n",
        "            if self.table[pos]['remainder'] == fr:\n",
        "                return True\n",
        "            if not self.table[pos]['continuation']:\n",
        "                break\n",
        "            pos = (pos + 1) % self.m\n",
        "        return False\n",
        "\n",
        "qf = QuotientFilter(q=3, p=5)\n",
        "elements = ['amsterdam', 'berlin', 'london', 'madrid', 'ankara', 'abu dhabi']\n",
        "\n",
        "for element in elements:\n",
        "    qf.add(element)\n",
        "\n",
        "print(f\"Contains 'berlin': {qf.contains('berlin')}\")\n",
        "print(f\"Contains 'paris': {qf.contains('paris')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5j14i5hWzSf",
        "outputId": "54372972-1d64-4c67-ded5-8f6bdcebf923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contains 'berlin': True\n",
            "Contains 'paris': False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### More Probabilistic Data Structures"
      ],
      "metadata": {
        "id": "uOJjHVembQ2p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are some more cool ones that I came across while researching."
      ],
      "metadata": {
        "id": "ThHibkeCbqST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Cuckoo filter**"
      ],
      "metadata": {
        "id": "oYfa4L3RchFI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A **cuckoo filter** is a space-efficient probabilistic data structure that is used to test whether an element is a member of a set, like a **Bloom filter** does.\n",
        "\n",
        "- Similar to **Bloom Filter** but supports deletion and is more space-efficient for certain scenarios.\n",
        "- Uses **cuckoo hashing** to handle collisions."
      ],
      "metadata": {
        "id": "gr8alD4acmK8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **LogLog**"
      ],
      "metadata": {
        "id": "cW2a1Ltcd7LR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, as you may have thought, this is similar to **HyperLogLog**.\n",
        "\n",
        "- Predecessor to **HyperLogLog** for cardinality estimation.\n",
        "- Less accurate but simpler."
      ],
      "metadata": {
        "id": "gtAO8Ewdd9-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **T-digest**"
      ],
      "metadata": {
        "id": "Xs3DWv_OfP-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The t-digest is an on-line algorithm for building **small sketches of data** that can be used to **approximate rank-based statistics** with high accuracy, particularly near the tails.\n",
        "\n",
        "It may help you find solutions to such questions:\n",
        "\n",
        "- Which fraction of the values in the data stream are smaller than a given value?\n",
        "- How many values in the data stream are smaller than a given value?\n",
        "- Which value is smaller than $p$ percent of the values in the data stream? What is the p-percentile value?\n",
        "- What is the mean value between the $p1$-percentile value and the $p2$-percentile value?\n",
        "- What is the value of the $n^{th}$ smallest (or largest) value in the data stream? What is the value with [reverse] rank $n$?\n"
      ],
      "metadata": {
        "id": "Io4VOb7SfkU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sources"
      ],
      "metadata": {
        "id": "V9T2WGQTgXPy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [Wikipedia.org](https://en.wikipedia.org/wiki/HyperLogLog)\n",
        "- [Brilliant.org](https://brilliant.org/wiki/bloom-filter)\n",
        "- [Medium.com](https://medium.com/@rrinlondon/count-min-sketch-5bf22743798a)\n",
        "- [Redis.io](https://redis.io/blog/t-digest-in-redis-stack/)\n",
        "- [Github.com](https://github.com/PetarWho)\n",
        "- [Youtube.com](https://www.youtube.com/)\n",
        "- [GeeksForGeeks.org](https://www.geeksforgeeks.org/bloom-filters-introduction-and-python-implementation/)\n",
        "- [cs.cmu.edu](https://www.cs.cmu.edu/~dga/papers/cuckoo-conext2014.pdf)"
      ],
      "metadata": {
        "id": "x0TLBjlxjLzG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UOx6TMMYiYse"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}