import pandas as pd
import numpy as np
import re
import seaborn as sns
import matplotlib.pyplot as plt











df = pd.read_csv("data/merged_data_cleaned.csv")





observations = df.shape[0]
features = df.shape[1]

print(f"Number of observations: {observations}")
print(f"Number of features: {features}")





def to_snake_case(column_name):
    column_name = re.sub(r'[\s\-\.]+', '_', column_name)
    column_name = column_name.lower()
    column_name = re.sub(r'[^a-z0-9_]', '', column_name)
    return column_name


df.columns = [to_snake_case(col) for col in df.columns]
print("Updated column names:", df.columns.tolist())





df['bag_weight'].unique()


def convert_weight_to_kg(value):
    if pd.isna(value):
        return None  # Handle missing values
    
    # Convert to string and strip spaces
    value = str(value).strip()

    # Handle special cases like '2 kg,lbs'
    if ',' in value:
        parts = value.split(',')
        value = parts[0]  # Assume the first part is the correct one
    
    # Extract numerical value and unit
    match = re.match(r'([\d.]+)\s*(kg|lbs)?', value.lower())
    
    if match:
        weight = float(match.group(1))  # Extract the numerical value
        unit = match.group(2)  # Extract the unit, if present

        # Convert to kilograms if necessary
        if unit == 'lbs':
            weight *= 0.453592  # Convert pounds to kilograms
        
        return weight
    
    return None  # If the format doesn't match, return None

# Apply the function to the 'bag_weight' column
df['bag_weight_cleaned'] = df['bag_weight'].apply(convert_weight_to_kg)

# Inspect the cleaned column
# print(df['bag_weight_cleaned'])
print(df['bag_weight_cleaned'].describe())






# Inspect unique values in the columns
print(df['harvest_year'].unique())
print(df['expiration'].unique())
print(df['grading_date'].unique())




def clean_harvest_year(value):
    if pd.isna(value):
        return np.nan
    
    value = str(value).strip().lower()

    # Match simple year
    match = re.match(r'^\d{4}$', value)
    if match:
        return int(match.group(0))
    
    # Match ranges like "2009/2010" or "2010-2011"
    match = re.match(r'^(\d{4})[-/](\d{2,4})$', value)
    if match:
        return int(match.group(1))  # Return the first year
    
    # Match year with month like "March 2010"
    match = re.search(r'(\d{4})', value)
    if match:
        return int(match.group(1))

    # If the value doesn't match any expected format, return NaN
    return np.nan

# Apply the cleaning function
df['harvest_year_cleaned'] = df['harvest_year'].apply(clean_harvest_year)

# Inspect the cleaned column
print(df[['harvest_year', 'harvest_year_cleaned']].dropna().head(10))


# Convert expiration_date to datetime
df['expiration_cleaned'] = pd.to_datetime(df['expiration'], errors='coerce')

# Convert grading_date to datetime
df['grading_date_cleaned'] = pd.to_datetime(df['grading_date'], errors='coerce')

# Inspect the cleaned columns
print(df[['expiration', 'expiration_cleaned']].head(10))
print(df[['grading_date', 'grading_date_cleaned']].head(10))






unknown_countries = df['country_of_origin'].isna().sum()

print(f"Number of coffees with unknown countries of origin: {unknown_countries}")






df_cleaned = df.dropna(subset=['country_of_origin'])

missing_country_count_after = df_cleaned['country_of_origin'].isna().sum()
print(f"Number of coffees with unknown countries of origin after dropping: {missing_country_count_after}")





df[['owner', 'owner_1', 'producer']]


df['owner_lower'] = df['owner'].str.lower()
df['owner_1_lower'] = df['owner_1'].str.lower()

differences_mask = df['owner_lower'] != df['owner_1_lower']

print(df[differences_mask][['owner', 'owner_1', 'producer']])


def clean_text(text):
    if pd.isna(text):
        return ''
    text = text.lower().strip()  # Convert to lowercase and strip whitespace
    text = re.sub(r'[^\w\s]', '', text)  # Remove special characters (except spaces)
    return text

df['owner_clean'] = df['owner'].apply(clean_text)
df['owner_1_clean'] = df['owner_1'].apply(clean_text)

# Update 'owner' with standardized 'owner_1' values if they match after cleaning
df['owner'] = df.apply(
    lambda row: row['owner_1'] if row['owner_clean'] == row['owner_1_clean'] and pd.notna(row['owner_1']) else row['owner'],
    axis=1
)

# Drop the helper columns used for comparison
df.drop(columns=['owner_clean', 'owner_1_clean'], inplace=True)

# Fill missing values in 'owner' if possible, here filling with 'Unknown' as an example
df['owner'].replace('', 'Unknown', inplace=True)

print(df[['owner', 'owner_1', 'producer']])








table_country = df.groupby(['country_of_origin', 'color']).size().reset_index(name='count')

print("Coffees by Color and Country:")
print(table_country)





rating_columns = [
    'aroma', 'flavor', 'aftertaste', 'acidity', 'body', 'balance', 'uniformity', 'clean_cup', 
    'sweetness', 'cupper_points', 'total_cup_points', 'moisture'
]

print("\nSummary Statistics for Rating Columns:")
for col in rating_columns:
    if col in df.columns:
        mean = df[col].mean()
        data_range = df[col].max() - df[col].min()
        print(f"\n{col}:")
        print(f"Mean: {mean:.2f}")
        print(f"Range: {data_range:.2f}")


# 2. Plot Histograms and Boxplots
plt.figure(figsize=(15, 10))

# Histograms
plt.subplot(2, 2, 1)
for col in rating_columns:
    if col in df.columns:
        plt.hist(df[col].dropna(), bins=20, alpha=0.5, label=col)
plt.title('Histograms of Rating Columns')
plt.xlabel('Rating')
plt.ylabel('Frequency')
plt.legend(loc='best')

# Boxplots
plt.subplot(2, 2, 2)
df[rating_columns].dropna().boxplot()
plt.title('Boxplots of Rating Columns')

plt.tight_layout()
plt.show()





# 3. Calculate Correlations (Optional)
print("\nCorrelation Matrix:")
correlation_matrix = df[rating_columns].corr()
print(correlation_matrix)

# Plot Correlation Heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Correlation Heatmap of Rating Columns')
plt.show()








# 1. Check Country and Region Consistency
print("\nChecking Country and Region Consistency:")
# Print unique regions and countries
unique_countries = df['country_of_origin'].dropna().unique()
unique_regions = df['region'].dropna().unique()
print(f"Unique countries: {unique_countries}")
print(f"Unique regions: {unique_regions}")

# Check if every region corresponds to a country
# For demonstration purposes, we'll just identify cases where region is NaN but country is not
inconsistent_entries = df[df['region'].isna() & df['country_of_origin'].notna()]
print(f"Entries with missing region but present country: {len(inconsistent_entries)}")
print(inconsistent_entries[['country_of_origin', 'region']])


# 2. Validate Altitudes

def convert_to_meters(value):
    if pd.isna(value) or value.strip() == '':
        return np.nan
    
    # Remove unwanted characters
    value = value.lower().replace('meters above sea level:', '').replace('msnm', '').replace('ft', '')
    
    # Convert feet to meters (1 ft = 0.3048 m)
    if 'ft' in value:
        try:
            return float(value.split()[0]) * 0.3048
        except ValueError:
            return np.nan
    
    # Extract numbers from ranges
    match = re.findall(r'\d+', value)
    if len(match) == 1:
        return float(match[0])
    elif len(match) == 2:
        low, high = float(match[0]), float(match[1])
        return (low + high) / 2  # Use mean of the range as representative value
    else:
        return np.nan

# Apply the conversion function to the 'Altitude' column
df['altitude_cleaned'] = df['altitude'].apply(convert_to_meters)

# Print cleaned altitudes
print("\nCleaned Altitudes:")
print(df[['altitude', 'altitude_cleaned']].head(20))

# Check for invalid values
invalid_altitudes = df[df['altitude_cleaned'].isna()]
print(f"\nEntries with invalid altitude values: {len(invalid_altitudes)}")
print(invalid_altitudes[['altitude', 'altitude_cleaned']])

# Check if altitude ranges are consistent (low < high)
inconsistent_altitudes = df[df['altitude_low_meters'] > df['altitude_high_meters']]
print(f"Entries with inconsistent altitude ranges: {len(inconsistent_altitudes)}")
print(inconsistent_altitudes[['altitude_low_meters', 'altitude_high_meters']])

print("\nSummary Statistics for Cleaned Altitudes:")
print(df['altitude_cleaned'].describe())


# 3. Validate Companies
print("\nValidating Company Names:")
# Check for missing company names and inconsistencies
missing_companies = df[df['company'].isna()]
print(f"Entries with missing company names: {len(missing_companies)}")
print(missing_companies[['company']])

# Check for duplicate company names or unexpected entries
duplicate_companies = df[df.duplicated(['company'], keep=False)]
print(f"Duplicate company entries: {len(duplicate_companies)}")
print(duplicate_companies[['company']])

# Print summary of findings
print("\nSummary of Findings:")
print(f"Unique countries: {len(unique_countries)}")
print(f"Unique regions: {len(unique_regions)}")
print(f"Entries with invalid altitude values: {len(invalid_altitudes)}")
print(f"Entries with inconsistent altitude ranges: {len(inconsistent_altitudes)}")
print(f"Entries with missing company names: {len(missing_companies)}")
print(f"Duplicate company entries: {len(duplicate_companies)}")





missing_values = df.isna().sum()
print("\nMissing Values by Column:")
print(missing_values[missing_values > 0])

# Fill missing values (fill NaN with the median)
df['altitude_cleaned'].fillna(df['altitude_cleaned'].median(), inplace=True)
df['altitude'] = df['altitude_cleaned']


# Check data types
print("\nData Types:")
print(df.dtypes)

# Convert columns to appropriate types (example: convert 'date' columns to datetime)
df['grading_date'] = pd.to_datetime(df['grading_date'], errors='coerce')
df['expiration'] = pd.to_datetime(df['expiration'], errors='coerce')

# Convert categorical columns to 'category' type
df['country_of_origin'] = df['country_of_origin'].astype('category')
df['color'] = df['color'].astype('category')



# Check for duplicates
duplicates = df[df.duplicated()]
print(f"\nDuplicate Rows: {len(duplicates)}")
print(duplicates.head())

# Drop duplicates if necessary
df_cleaned = df.drop_duplicates()



# Set the columns of the dataframe to the cleaned ones
df['grading_date'] = df['grading_date_cleaned']
df['expiration'] = df['expiration_cleaned']
df['harvest_year'] = df['harvest_year_cleaned']
df['bag_weight'] = df['bag_weight_cleaned']


df = df.columns.drop(['owner_lower', 'owner_1_lower', 'grading_date_cleaned', 'expiration_cleaned', 'harvest_year_cleaned', 'bag_weight_cleaned', 'altitude_cleaned'])


df



